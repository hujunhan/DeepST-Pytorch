{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hu\\miniconda3\\envs\\pytorch11\\lib\\site-packages\\h5py\\_hl\\dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6624 6624\n",
      "(5616, 6, 32, 32)\n",
      "(5616, 6, 32, 32)\n",
      "(5616, 6, 32, 32)\n",
      "(5616,)\n",
      "(5616, 2, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "data_Path='../data/TaxiBJ/BJ16_M32x32_T30_InOut.h5'\n",
    "def del_incomp_date(data_Path):\n",
    "    reader=h5py.File(data_Path,'r')\n",
    "    data=reader['data'].value\n",
    "    date=reader['date'].value\n",
    "    reader.close()\n",
    "    data=np.array(data)\n",
    "    date=np.array(date)\n",
    "    date_complete=[]##完整的天数\n",
    "    data_complete=[]\n",
    "    date_temp=[]##用于统计一天是否有48个时间戳\n",
    "    data_temp=[]\n",
    "    date_str=date[0][0:8]\n",
    "    for i in range(len(date)):\n",
    "        if date[i][0:8]==date_str:\n",
    "            date_temp.append(date[i])\n",
    "            data_temp.append(data[i])\n",
    "        else :\n",
    "            if len(date_temp)==48:\n",
    "                date_complete.extend(date_temp)\n",
    "                data_complete.extend(data_temp)\n",
    "            date_temp.clear()\n",
    "            data_temp.clear()\n",
    "            date_str=date[i][0:8]\n",
    "            date_temp.append(date[i])\n",
    "            data_temp.append(data[i])\n",
    "    print(len(date_complete),len(data_complete))\n",
    "    return data_complete,date_complete\n",
    "data,date = del_incomp_date(data_Path)\n",
    "close_data=[]\n",
    "period_data=[]\n",
    "trend_data=[]\n",
    "Y=data[1008:]\n",
    "time_stamps=[]\n",
    "close=[i for i in range(1,4)]\n",
    "period=[48*j for j in range(1,4)]\n",
    "trend=[7*48*j for j in range(1,4)]\n",
    "close_temp=np.array([])\n",
    "period_temp=np.array([])\n",
    "trend_temp=np.array([])\n",
    "data=np.array(data)\n",
    "for i in range(1008,(len(data))):\n",
    "    close_temp=np.vstack([data[i-j] for j in close])\n",
    "    period_temp=np.vstack([data[i-j] for j in period])\n",
    "    trend_temp=np.vstack([data[i-j] for j in trend])\n",
    "    close_data.append(close_temp)\n",
    "    period_data.append(period_temp)\n",
    "    trend_data.append(trend_temp)\n",
    "    time_stamps.append(date[i])\n",
    "print(np.asarray(close_data).shape)\n",
    "print(np.asarray(period_data).shape)\n",
    "print(np.asarray(trend_data).shape)\n",
    "print(np.asarray(time_stamps).shape)\n",
    "print(np.asarray(Y).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 模型建立\n",
    "### 3.1 基本Pytorch网络模型\n",
    "    在代码实现模型之前，还是得先复习一下论文中的模型是怎样的。\n",
    "    这篇论文的关键创新之处就是提出了“Spatio-Temporal Residual Networks”，基于时间 、空间的残差网络模型。\n",
    "    对于close、period、trend三条分支来说，其实他们的模型是一样的，无非输入矩阵的维数可以不同而已。他们的模型有两个组成部分：\n",
    "1. convolution 卷积层，将城市的车流信息看成是一张图片，这个部分获取了车流信息的位置联系，卷积核为3x3，最后以一个tanh函数结尾\n",
    "2. residual unit 残差块，可以训练出非常深的卷积神经网络，在这个模型中，一个残差块被定义为ReLU->Conv->ReLU->Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import  nn\n",
    "import torch as t\n",
    "from torch.nn import  functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    首先下面的代码定义了一个残差块，其中用到了2维卷积、Relu.\n",
    "    这个项目中输入Channel=6，Width=Height=32，输出Channel=2，Width=Height=32\n",
    "    根据输入输出公式\n",
    "![shape](img/conv-shape.jpg)\n",
    "\n",
    "> class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "\n",
    "    因为要保持输出还是32x32，选择padding=1，kernel-size=3，stride=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5616, 6, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "close_data=np.asarray(close_data)\n",
    "close_data=np.float32(close_data)\n",
    "print(close_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUnit(nn.Module):\n",
    "    def __init__(self,in_flow,out_flow,stride=1,shortcut=True):\n",
    "        super(ResUnit,self).__init__()\n",
    "        self.left=nn.Sequential(\n",
    "                nn.Conv2d(in_flow,out_flow,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(out_flow),\n",
    "                nn.Conv2d(out_flow,out_flow,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "                nn.BatchNorm2d(out_flow)).float()\n",
    "        self.right=shortcut\n",
    "    def forward(self,x):\n",
    "        out=self.left(x)\n",
    "        residual=x\n",
    "        out+=residual\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=ResUnit(6,2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "a=t.from_numpy(close_data[0])\n",
    "a.unsqueeze_(0)\n",
    "a.requires_grad_(True)\n",
    "a.float()\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResUnit(\n",
      "  (left): Sequential(\n",
      "    (0): Conv2d(6, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([2, 6, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "para=list(res.parameters())\n",
    "print(len(para))\n",
    "print(para[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (6) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4057827722cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hu\\miniconda3\\envs\\pytorch11\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-5f51058dce09>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mresidual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mresidual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (6) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "out=res(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 feature模块 \n",
    "    之前我们只使用了流量数据，没有看过天气情况，现在来看一看 BJ_Meteorology.h5 这个模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'BJ_Meteorology.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7156d1255430>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfeature_Path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'BJ_Meteorology.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mreader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_Path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hu\\miniconda3\\envs\\pytorch11\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hu\\miniconda3\\envs\\pytorch11\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'BJ_Meteorology.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "feature_Path='BJ_Meteorology.h5'\n",
    "reader=h5py.File(feature_Path,'r')\n",
    "for key in reader.keys():\n",
    "    print(key,reader[key].shape,reader[key].dtype)\n",
    "temperature=reader['Temperature'].value\n",
    "weather=reader['Weather'].value\n",
    "windspeed=reader['WindSpeed'].value\n",
    "feature_date=reader['date'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'2013020105' b'2013020106' b'2013020107' b'2013020108' b'2013020109'\n",
      " b'2013020110' b'2013020111' b'2013020112' b'2013020113' b'2013020114']\n"
     ]
    }
   ],
   "source": [
    "print(feature_date[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    看来这个文件里有4个部分，温度、天气、风速和时间戳。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 2\n"
     ]
    }
   ],
   "source": [
    "ws=[]\n",
    "wr=[]\n",
    "te=[]\n",
    "M=dict()\n",
    "for i, slot in enumerate(date):\n",
    "    M[slot] = i\n",
    "for i in time_stamps:\n",
    "    feature_index=M[i]-1\n",
    "    ws.append([windspeed[feature_index]])\n",
    "    wr.append(weather[feature_index])\n",
    "    te.append([temperature[feature_index]])\n",
    "ws=np.array(ws)\n",
    "wr=np.array(wr)\n",
    "te=np.array(te)\n",
    "ws=1.*(ws-ws.min())/(ws.max()-ws.min())\n",
    "te=1.*(te-te.min())/(te.max()-te.min())\n",
    "print(ws.ndim,wr.ndim,te.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5616, 19)\n"
     ]
    }
   ],
   "source": [
    "merge_data=np.hstack([wr,ws,te])\n",
    "print(merge_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ext(nn.Module):\n",
    "    def __init__(self,ext_dim):\n",
    "        super(Ext,self).__init__()\n",
    "        self.left=nn.Sequential(\n",
    "                nn.Linear(in_features=ext_dim,out_features=10),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(in_features=10,out_features=2*32*32),\n",
    "                nn.ReLU(inplace=True))\n",
    "    def forward(self,x):\n",
    "        out=self.left(x)\n",
    "        out=out.resize(2,32,32)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[[ 0.0000,  0.1968,  0.0000,  ...,  0.0263,  0.3032,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.2061,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1103,  0.2472,  0.0000,  ...,  0.0000,  0.0000,  0.2043],\n",
      "         ...,\n",
      "         [ 0.0000,  0.2538,  0.0000,  ...,  0.0000,  0.1619,  0.0000],\n",
      "         [ 0.2141,  0.2319,  0.1209,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.2215,  0.2876,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.2629,  0.0000,  0.0231,  ...,  0.1065,  0.1766,  0.1736],\n",
      "         [ 0.2016,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0062],\n",
      "         [ 0.0552,  0.2549,  0.0000,  ...,  0.1095,  0.0000,  0.2663],\n",
      "         ...,\n",
      "         [ 0.2389,  0.0000,  0.0000,  ...,  0.0000,  0.1941,  0.3339],\n",
      "         [ 0.0000,  0.2345,  0.2899,  ...,  0.0105,  0.1450,  0.1565],\n",
      "         [ 0.0000,  0.0983,  0.0672,  ...,  0.0195,  0.0000,  0.0000]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\胡钧涵\\AppData\\Roaming\\Python\\Python36\\site-packages\\torch\\tensor.py:255: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model=Ext(19)\n",
    "a=torch.tensor(merge_data[0])\n",
    "a=np.float32(a)\n",
    "a=torch.tensor(a)\n",
    "print(a.dtype)\n",
    "out1=model(a)\n",
    "print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20]) torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(input.size(),output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    如上我们简单的使用时间戳的数据流进行了多次计算，接下来，再来看看多个输入时如何fuse在一起的\n",
    "### 3.3 输出之fuse\n",
    "   ![fuse](img/fuse.jpg)\n",
    "        \n",
    "       如论文所示，每个输入要用一个系数哈达玛积之后加起来。\n",
    "       那啥是Hadamard积呢，wiki告诉我\n",
    "   ![hadamard](img/hadamard.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4988,  0.9987],\n",
      "        [ 0.5203, -0.0643]])\n",
      "tensor([[ 1.1245, -0.1687],\n",
      "        [-0.8883,  0.4992]])\n"
     ]
    }
   ],
   "source": [
    "c=t.randn(2,2)\n",
    "b=t.randn(2,2)\n",
    "print(c)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5609, -0.1685],\n",
      "        [-0.4622, -0.0321]])\n"
     ]
    }
   ],
   "source": [
    "d=t.mul(b,c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    显然，torch.mul干的就是hadamard积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 32, 32)\n",
      "(3, 2, 32, 32)\n",
      "(3, 2, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "c_conf=(3, 2, 32, 32)\n",
    "p_conf=(3, 2, 32, 32)\n",
    "t_conf=(3, 2, 32, 32)\n",
    "for conf in [c_conf, p_conf, t_conf]:\n",
    "    print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.4 定义Loss function\n",
    "    通过我们定义的网络输出的值要和预测值比较，计算损失函数，然后再反向传播，优化参数。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_data=t.from_numpy(close_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.float32(data)\n",
    "data=t.from_numpy(data)\n",
    "criterion=nn.MSELoss()\n",
    "loss=criterion(out1,data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(308.8104)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  0.,   2.,   4.,  ...,   1.,   1.,   9.],\n",
      "         [  0.,   4.,   5.,  ...,   2.,   2.,  20.],\n",
      "         [  0.,   1.,   1.,  ...,   2.,  51.,  37.],\n",
      "         ...,\n",
      "         [  1.,   1.,   3.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   2.,   2.,  ...,   2.,   0.,   1.],\n",
      "         [  0.,   2.,   1.,  ...,   1.,   2.,   2.]],\n",
      "\n",
      "        [[  0.,   2.,   5.,  ...,   1.,   1.,   9.],\n",
      "         [  0.,   4.,   6.,  ...,   2.,   2.,  21.],\n",
      "         [  0.,   1.,   1.,  ...,   2.,  50.,  39.],\n",
      "         ...,\n",
      "         [  1.,   1.,   3.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   2.,   2.,  ...,   2.,   0.,   1.],\n",
      "         [  0.,   2.,   1.,  ...,   1.,   2.,   1.]]])\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   \n",
    "loss.backward()# zero the gradient buffers\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.1973,  0.0000,  ...,  0.0256,  0.3030,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.2066,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1102,  0.2469,  0.0000,  ...,  0.0000,  0.0000,  0.2050],\n",
      "         ...,\n",
      "         [ 0.0000,  0.2534,  0.0000,  ...,  0.0000,  0.1620,  0.0000],\n",
      "         [ 0.2142,  0.2321,  0.1210,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.2216,  0.2878,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.2632,  0.0000,  0.0229,  ...,  0.1066,  0.1768,  0.1732],\n",
      "         [ 0.2012,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0067],\n",
      "         [ 0.0550,  0.2550,  0.0000,  ...,  0.1093,  0.0000,  0.2666],\n",
      "         ...,\n",
      "         [ 0.2387,  0.0000,  0.0000,  ...,  0.0000,  0.1939,  0.3336],\n",
      "         [ 0.0000,  0.2351,  0.2897,  ...,  0.0111,  0.1448,  0.1566],\n",
      "         [ 0.0000,  0.0981,  0.0669,  ...,  0.0190,  0.0000,  0.0000]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\胡钧涵\\AppData\\Roaming\\Python\\Python36\\site-packages\\torch\\tensor.py:255: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "out=model(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
